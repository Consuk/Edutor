
# ğŸ“š Edutor â€“ Intelligent Teaching Plan Generator from Books

Este proyecto transforma libros en PDF en una herramienta de planificaciÃ³n educativa, usando procesamiento de lenguaje natural (NLP), visualizaciones y modelos de IA generativa (como Gemini) para generar contenidos pedagÃ³gicos como planes de clase, resÃºmenes y evaluaciones.

---

## ğŸ§  Objetivo

Automatizar la generaciÃ³n de materiales educativos a partir de libros, extrayendo sus ideas principales, visualizando su contenido y seleccionando bloques relevantes mediante IA para producir:

- Planificaciones semanales
- ExÃ¡menes y actividades
- ResÃºmenes por temas
- AnÃ¡lisis lÃ©xico del contenido

---

## âš™ï¸ TecnologÃ­as y librerÃ­as utilizadas

- **Python 3 + Jupyter Notebook**
- `PyMuPDF` (`fitz`) â€“ ExtracciÃ³n de texto desde PDFs
- `NLTK` â€“ TokenizaciÃ³n, stopwords y anÃ¡lisis textual (visualizaciÃ³n)
- `Matplotlib`, `Seaborn`, `WordCloud` â€“ VisualizaciÃ³n de datos lingÃ¼Ã­sticos
- `LangChain` â€“ DivisiÃ³n semÃ¡ntica de texto en chunks
- `scikit-learn` â€“ TF-IDF, similitud de coseno, PCA, KMeans
- **Google Vertex AI** (`text-multilingual-embedding-002`) â€“ Embeddings semÃ¡nticos
- `Google GenAI` o Gemini â€“ GeneraciÃ³n de contenido educativo

---

## ğŸ§© Estructura del pipeline

### 1. ğŸ“„ **Carga del libro PDF**
Se usa PyMuPDF para extraer todo el texto plano del PDF.

```python
full_text = extract_text_from_pdf(pdf_path)
```

---

### 2. ğŸ”  **AnÃ¡lisis textual bÃ¡sico**

Se generan visualizaciones exploratorias para entender el contenido:

- Frecuencia de palabras
- Nube de palabras
- DistribuciÃ³n de longitud de oraciones
- EvoluciÃ³n de vocabulario
- Tendencias de palabras por chunks

```python
run_visualizations(pdf_path)
```

---

### 3. ğŸ“š **DivisiÃ³n semÃ¡ntica del libro**

Se divide el texto en fragmentos ("chunks") con solapamiento para preservar contexto semÃ¡ntico.

```python
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
docs = splitter.create_documents([full_text])
```

---

### 4. ğŸ§¹ **Limpieza heurÃ­stica**

Se eliminan secciones irrelevantes como Ã­ndices, agradecimientos, portadas, usando heurÃ­sticas:

```python
docs = clean_and_sequence_docs(docs)
```

---

### 5. ğŸ” **Filtrado por relevancia con TF-IDF**

Se define una query educativa. Se filtran los chunks con mayor relevancia usando TF-IDF.

```python
query = "Generate a semester-long teaching plan using the main ideas and structure of this book"
```

---

### 6. ğŸ§  **Filtrado semÃ¡ntico con embeddings**

Se generan embeddings con Gemini (Vertex AI) y se filtran los mÃ¡s cercanos al centro semÃ¡ntico del grupo.

```python
pre_embeddings = embed_in_batches(pre_tfidf_chunks)
```

---

### 7. ğŸ“Š **VisualizaciÃ³n avanzada**

Se grafican:

- Histogramas y scatterplots de similitud semÃ¡ntica
- Mapas de calor de similitud entre chunks
- ReducciÃ³n PCA de embeddings
- Clustering KMeans para encontrar grupos temÃ¡ticos
- Palabras clave dominantes por TF-IDF

---

### 8. ğŸ“Œ **PonderaciÃ³n semÃ¡ntica + estructura**

Los chunks seleccionados se ponderan por:
- 70% similitud semÃ¡ntica
- 30% proximidad a la estructura original del libro

Esto mejora la coherencia narrativa del contenido final (`context`).

---

### 9. âœ¨ **GeneraciÃ³n con IA**

El `context` final se usa como entrada a modelos generativos como Gemini para producir materiales educativos:

```python
response = model.generate_content(prompt_with_context)
```

---

## ğŸ”® Posibilidades de expansiÃ³n

- Crear una API (FastAPI) para recibir libros y devolver contenidos educativos.
- Soporte multilingÃ¼e y multigrado (primaria, secundaria...).
- Panel de control visual con React js.
- GeneraciÃ³n de preguntas por niveles de Bloom.

---

## ğŸ“ Archivos importantes

| Archivo         | DescripciÃ³n |
|----------------|-------------|
| `Edutor.ipynb` | Notebook principal que contiene todo el pipeline |
| `Books/`       | Carpeta con libros PDF de entrada |
| `context`      | Texto filtrado y listo para generaciÃ³n AI |

---

## ğŸ“¢ Requisitos

```bash
pip install pymupdf nltk langchain vertexai google-cloud-aiplatform \
                matplotlib seaborn scikit-learn wordcloud
```

AdemÃ¡s, se necesita configurar credenciales para usar Google Vertex AI:

```python
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "KEY_HERE.json"
```

---

## ğŸ§‘â€ğŸ« Autores y crÃ©ditos

Este proyecto fue desarrollado como parte del sistema **Edutor**, con la misiÃ³n de facilitar el trabajo docente mediante herramientas inteligentes.

Por: Constanza Corvera y Pablo T. Kusulas.

---
